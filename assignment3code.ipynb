{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f823ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\116su\\source\\repos\\Assignment_3_Code\\venv\\Lib\\site-packages\\stopwordsiso\\_core.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add additional imports under here\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import stopwordsiso as stopwords\n",
    "from deep_translator import GoogleTranslator\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from googletrans import Translator\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab760bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CILUBA', 'French', 'Score', 'Sentiment', 'Nature']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CILUBA</th>\n",
       "      <th>French</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Nature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Akaja</td>\n",
       "      <td>Arrange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akajilula</td>\n",
       "      <td>Rearrange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akula</td>\n",
       "      <td>Parle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akulula</td>\n",
       "      <td>Reparle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aluja</td>\n",
       "      <td>Remet</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CILUBA     French  Score Sentiment Nature\n",
       "0      Akaja    Arrange    1.0   Positif  Verbe\n",
       "1  Akajilula  Rearrange    1.0   Positif  Verbe\n",
       "2      Akula      Parle    2.0   Positif  Verbe\n",
       "3    Akulula    Reparle    2.0   Positif  Verbe\n",
       "4      Aluja      Remet    3.0   Positif  Verbe"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading\n",
    "df = pd.read_excel(\"lexicon_6000 words.xlsx\")\n",
    "\n",
    "#keep a copy of the original columns\n",
    "original_Cols = df.columns.tolist()\n",
    "print(original_Cols)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45a9c1ac-1778-4554-84a3-c539b92f62e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n",
      "dataset size: 6963\n",
      "new dataset size: 6646\n"
     ]
    }
   ],
   "source": [
    "dup_Count = df.duplicated().sum()\n",
    "print(dup_Count)\n",
    "\n",
    "if dup_Count > 0:\n",
    "    print(\"dataset size:\", len(df)) \n",
    "    df = df.drop_duplicates()\n",
    "    print(\"new dataset size:\", len(df))\n",
    "\n",
    "#taking away any duplication/ spacing errors\n",
    "col_Strings = df.select_dtypes(include=['object']).columns\n",
    "for col in col_Strings:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "    df[col] = df[col].str.replace(r'\\s+','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02b7927d-ca65-4ad1-9706-c1fe52fe398d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CILUBA</th>\n",
       "      <th>French</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Nature</th>\n",
       "      <th>English</th>\n",
       "      <th>Zulu</th>\n",
       "      <th>Afrikaans</th>\n",
       "      <th>Sepedi</th>\n",
       "      <th>Xhosa</th>\n",
       "      <th>Shona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Akaja</td>\n",
       "      <td>Arrange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akajilula</td>\n",
       "      <td>Rearrange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akula</td>\n",
       "      <td>Parle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akulula</td>\n",
       "      <td>Reparle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aluja</td>\n",
       "      <td>Remet</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CILUBA     French  Score Sentiment Nature  English  Zulu  Afrikaans  \\\n",
       "0      Akaja    Arrange    1.0   Positif  Verbe      NaN   NaN        NaN   \n",
       "1  Akajilula  Rearrange    1.0   Positif  Verbe      NaN   NaN        NaN   \n",
       "2      Akula      Parle    2.0   Positif  Verbe      NaN   NaN        NaN   \n",
       "3    Akulula    Reparle    2.0   Positif  Verbe      NaN   NaN        NaN   \n",
       "4      Aluja      Remet    3.0   Positif  Verbe      NaN   NaN        NaN   \n",
       "\n",
       "   Sepedi  Xhosa  Shona  \n",
       "0     NaN    NaN    NaN  \n",
       "1     NaN    NaN    NaN  \n",
       "2     NaN    NaN    NaN  \n",
       "3     NaN    NaN    NaN  \n",
       "4     NaN    NaN    NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_Languages = [\"English\", \"Zulu\", \"Afrikaans\", \"Sepedi\", \"Xhosa\", \"Shona\"]\n",
    "\n",
    "for lang in new_Languages:\n",
    "    if lang not in df.columns:\n",
    "        df[lang] = np.nan\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00be8d77-8f9e-44e4-b9e6-af7fdbdd00c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate_French_To_English(text):\n",
    "    if pd.isna(text) or text.strip==\"\":\n",
    "        return np.man\n",
    "    try:\n",
    "        return GoogleTranslator(source='fr', target='en').translate(text)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def translate_English_To_Language(text, language_Code):\n",
    "    if pd.isna(text) or text.strip()==\"\":\n",
    "        return np.man\n",
    "    try:\n",
    "        return GoogleTranslator(source=\"en\", target=language_Code).translate(text)\n",
    "    except Exception:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e503ceee-7173-41f4-9397-af2025888e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df[\"English\"] = df[\"French\"].progress_apply(translate_French_To_English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e64bcf-515b-4e3a-8f1a-e18e60627d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors occured: 0\n",
      "Unique English words: 3864\n"
     ]
    }
   ],
   "source": [
    "print(\"Errors occured:\", df[\"English\"].isna().sum())\n",
    "print(\"Unique English words:\", df[\"English\"].nunique(dropna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428536c-451a-4986-9438-4310d8ae9eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6632/6632 [2:25:27<00:00,  1.32s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6632/6632 [2:15:14<00:00,  1.22s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6632/6632 [2:04:38<00:00,  1.13s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6632/6632 [2:26:53<00:00,  1.33s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6632/6632 [2:19:04<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "language_Code = {\"Zulu\":\"zu\", \"Afrikaans\":\"af\", \"Sepedi\":\"nso\", \"Xhosa\":\"xh\", \"Shona\":\"sn\"}\n",
    "\n",
    "for lang, code in language_Code.items():\n",
    "    df[lang] = df[\"English\"].progress_apply(lambda x: translate_English_To_Language(x, code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471082a0-bace-4112-b867-736dfd4bf75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CILUBA</th>\n",
       "      <th>French</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Nature</th>\n",
       "      <th>English</th>\n",
       "      <th>Zulu</th>\n",
       "      <th>Afrikaans</th>\n",
       "      <th>Sepedi</th>\n",
       "      <th>Xhosa</th>\n",
       "      <th>Shona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Akaja</td>\n",
       "      <td>Arrange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Arrange</td>\n",
       "      <td>Hlela</td>\n",
       "      <td>Reël</td>\n",
       "      <td>Beakanya</td>\n",
       "      <td>Cwangcisa</td>\n",
       "      <td>Ronga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akajilula</td>\n",
       "      <td>Rearrange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Rear range</td>\n",
       "      <td>Ibanga langemuva</td>\n",
       "      <td>Grootafstand</td>\n",
       "      <td>Range ya ka morao .</td>\n",
       "      <td>Uluhlu lwangasemva</td>\n",
       "      <td>Kumashure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akula</td>\n",
       "      <td>Parle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Speak</td>\n",
       "      <td>Khuluma</td>\n",
       "      <td>Praat</td>\n",
       "      <td>Bolela</td>\n",
       "      <td>Thetha</td>\n",
       "      <td>Taura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akulula</td>\n",
       "      <td>Reparle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Speak again</td>\n",
       "      <td>Khuluma futhi</td>\n",
       "      <td>Praat weer</td>\n",
       "      <td>Bolela gape .</td>\n",
       "      <td>Thetha kwakhona</td>\n",
       "      <td>Taura zvakare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aluja</td>\n",
       "      <td>Remet</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Hands over</td>\n",
       "      <td>Izandla ngaphezulu</td>\n",
       "      <td>Hande om</td>\n",
       "      <td>diatla godimo ga .</td>\n",
       "      <td>Izandla ngaphezulu</td>\n",
       "      <td>Maoko pamusoro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amba</td>\n",
       "      <td>Dis</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Say</td>\n",
       "      <td>Khuluma</td>\n",
       "      <td>Sê</td>\n",
       "      <td>Bolela</td>\n",
       "      <td>Yithi</td>\n",
       "      <td>Taura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ambakaja</td>\n",
       "      <td>Supperpose</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Suppose</td>\n",
       "      <td>Cabanga</td>\n",
       "      <td>Veronderstel</td>\n",
       "      <td>Nagana</td>\n",
       "      <td>Cinga</td>\n",
       "      <td>Ngatitii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ambula</td>\n",
       "      <td>Ramasse</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Pick up</td>\n",
       "      <td>Phakamisa</td>\n",
       "      <td>Optel</td>\n",
       "      <td>Topa</td>\n",
       "      <td>Phakamisa</td>\n",
       "      <td>Nhonga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ambuluja</td>\n",
       "      <td>Depeche</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Depeche</td>\n",
       "      <td>I-depeche</td>\n",
       "      <td>Depeche</td>\n",
       "      <td>Depeche .</td>\n",
       "      <td>I-dope</td>\n",
       "      <td>Zvinorevache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ambulula</td>\n",
       "      <td>Repete</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Repeated</td>\n",
       "      <td>-Phindaphiwe</td>\n",
       "      <td>Herhaal</td>\n",
       "      <td>pheta-pheta .</td>\n",
       "      <td>Iphindaphindwe</td>\n",
       "      <td>Kudzokororwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Andamuna</td>\n",
       "      <td>Repond</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Answers</td>\n",
       "      <td>Ukuphendula</td>\n",
       "      <td>Antwoorde</td>\n",
       "      <td>Dikarabo .</td>\n",
       "      <td>Iimpendulo</td>\n",
       "      <td>Mhinduro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Angata</td>\n",
       "      <td>Prend</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Takes</td>\n",
       "      <td>Izakahlela</td>\n",
       "      <td>Neem</td>\n",
       "      <td>E tšea .</td>\n",
       "      <td>Ithatha</td>\n",
       "      <td>Zvinotora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Angatulula</td>\n",
       "      <td>Reprend</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Resume</td>\n",
       "      <td>Qalela phansi</td>\n",
       "      <td>Hervat</td>\n",
       "      <td>Thomološa</td>\n",
       "      <td>Phinda Uqalele</td>\n",
       "      <td>Tangazve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bilamba</td>\n",
       "      <td>Habits</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Mot</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>Izingubo</td>\n",
       "      <td>Klere</td>\n",
       "      <td>Diaparo</td>\n",
       "      <td>Iimpahla</td>\n",
       "      <td>Zvipfeko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bilela</td>\n",
       "      <td>Blague</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Mot</td>\n",
       "      <td>Joke</td>\n",
       "      <td>Ihlaya</td>\n",
       "      <td>Grap</td>\n",
       "      <td>Metlae</td>\n",
       "      <td>Hlekisa</td>\n",
       "      <td>Joke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Biluatu</td>\n",
       "      <td>Vetements</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Mot</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>Izingubo</td>\n",
       "      <td>Klere</td>\n",
       "      <td>Diaparo</td>\n",
       "      <td>Iimpahla</td>\n",
       "      <td>Zvipfeko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Binsonji</td>\n",
       "      <td>Larmes</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Mot</td>\n",
       "      <td>Tears</td>\n",
       "      <td>Izinyembekathi</td>\n",
       "      <td>Trane</td>\n",
       "      <td>Megokgo</td>\n",
       "      <td>Iinyembezi</td>\n",
       "      <td>Misodzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Buela</td>\n",
       "      <td>Entre</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Between</td>\n",
       "      <td>Ngaphakathi</td>\n",
       "      <td>Tussen</td>\n",
       "      <td>Magareng</td>\n",
       "      <td>Phakathi</td>\n",
       "      <td>Pakati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bukenka</td>\n",
       "      <td>Lumiere</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Mot</td>\n",
       "      <td>Light</td>\n",
       "      <td>-Mhlophe</td>\n",
       "      <td>Lig</td>\n",
       "      <td>Seetša</td>\n",
       "      <td>Ukukhanya</td>\n",
       "      <td>Chiedza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Buloba</td>\n",
       "      <td>Terre</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Mot</td>\n",
       "      <td>Earth</td>\n",
       "      <td>Inhlabathi</td>\n",
       "      <td>Aarde</td>\n",
       "      <td>Lefase</td>\n",
       "      <td>Umhlaba</td>\n",
       "      <td>Pasi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CILUBA      French  Score Sentiment Nature      English  \\\n",
       "0        Akaja     Arrange    1.0   Positif  Verbe      Arrange   \n",
       "1    Akajilula   Rearrange    1.0   Positif  Verbe   Rear range   \n",
       "2        Akula       Parle    2.0   Positif  Verbe        Speak   \n",
       "3      Akulula     Reparle    2.0   Positif  Verbe  Speak again   \n",
       "4        Aluja       Remet    3.0   Positif  Verbe   Hands over   \n",
       "5         Amba         Dis    3.0   Positif  Verbe          Say   \n",
       "6     Ambakaja  Supperpose    3.0   Positif  Verbe      Suppose   \n",
       "7       Ambula     Ramasse    4.0   Positif  Verbe      Pick up   \n",
       "8     Ambuluja     Depeche    4.0   Positif  Verbe      Depeche   \n",
       "9     Ambulula      Repete    9.0   Positif  Verbe     Repeated   \n",
       "10    Andamuna      Repond    9.0   Positif  Verbe      Answers   \n",
       "11      Angata       Prend    9.0   Positif  Verbe        Takes   \n",
       "12  Angatulula     Reprend    9.0   Positif  Verbe       Resume   \n",
       "13     Bilamba      Habits    8.0   Positif    Mot      Clothes   \n",
       "14      Bilela      Blague    8.0   Positif    Mot         Joke   \n",
       "15     Biluatu   Vetements   -1.0   Negatif    Mot      Clothes   \n",
       "16    Binsonji      Larmes    7.0   Positif    Mot        Tears   \n",
       "17       Buela       Entre    7.0   Positif  Verbe      Between   \n",
       "18     Bukenka     Lumiere    7.0   Positif    Mot        Light   \n",
       "19      Buloba       Terre   -1.0   Negatif    Mot        Earth   \n",
       "\n",
       "                  Zulu     Afrikaans               Sepedi               Xhosa  \\\n",
       "0                Hlela          Reël             Beakanya           Cwangcisa   \n",
       "1     Ibanga langemuva  Grootafstand  Range ya ka morao .  Uluhlu lwangasemva   \n",
       "2              Khuluma         Praat               Bolela              Thetha   \n",
       "3        Khuluma futhi    Praat weer        Bolela gape .     Thetha kwakhona   \n",
       "4   Izandla ngaphezulu      Hande om   diatla godimo ga .  Izandla ngaphezulu   \n",
       "5              Khuluma            Sê               Bolela               Yithi   \n",
       "6              Cabanga  Veronderstel               Nagana               Cinga   \n",
       "7            Phakamisa         Optel                 Topa           Phakamisa   \n",
       "8            I-depeche       Depeche            Depeche .              I-dope   \n",
       "9         -Phindaphiwe       Herhaal        pheta-pheta .      Iphindaphindwe   \n",
       "10         Ukuphendula     Antwoorde           Dikarabo .          Iimpendulo   \n",
       "11          Izakahlela          Neem             E tšea .             Ithatha   \n",
       "12       Qalela phansi        Hervat            Thomološa      Phinda Uqalele   \n",
       "13            Izingubo         Klere              Diaparo            Iimpahla   \n",
       "14              Ihlaya          Grap               Metlae             Hlekisa   \n",
       "15            Izingubo         Klere              Diaparo            Iimpahla   \n",
       "16      Izinyembekathi         Trane              Megokgo          Iinyembezi   \n",
       "17         Ngaphakathi        Tussen             Magareng            Phakathi   \n",
       "18            -Mhlophe           Lig               Seetša           Ukukhanya   \n",
       "19          Inhlabathi         Aarde               Lefase             Umhlaba   \n",
       "\n",
       "             Shona  \n",
       "0            Ronga  \n",
       "1        Kumashure  \n",
       "2            Taura  \n",
       "3    Taura zvakare  \n",
       "4   Maoko pamusoro  \n",
       "5            Taura  \n",
       "6         Ngatitii  \n",
       "7           Nhonga  \n",
       "8     Zvinorevache  \n",
       "9     Kudzokororwa  \n",
       "10        Mhinduro  \n",
       "11       Zvinotora  \n",
       "12        Tangazve  \n",
       "13        Zvipfeko  \n",
       "14            Joke  \n",
       "15        Zvipfeko  \n",
       "16         Misodzi  \n",
       "17          Pakati  \n",
       "18         Chiedza  \n",
       "19            Pasi  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c92af-2705-4fba-8f51-5103ffc7ace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zulu: missing 1\n",
      "Afrikaans: missing 0\n",
      "Sepedi: missing 0\n",
      "Xhosa: missing 1\n",
      "Shona: missing 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "English      3864\n",
       "Zulu         3513\n",
       "Afrikaans    3647\n",
       "Sepedi       3376\n",
       "Xhosa        3367\n",
       "Shona        3156\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing translations (NaN)\n",
    "for lang in [\"Zulu\",\"Afrikaans\",\"Sepedi\",\"Xhosa\",\"Shona\"]:\n",
    "    print(f\"{lang}: missing {df[lang].isna().sum()}\")\n",
    "\n",
    "# unique counter\n",
    "df[[\"English\",\"Zulu\",\"Afrikaans\",\"Sepedi\",\"Xhosa\",\"Shona\"]].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b43ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "positive    4361\n",
      "neutral     1121\n",
      "negative    1116\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_lexicon = pd.read_excel('./lexicon_dataset/expanded_lexicon.xlsx')\n",
    "\n",
    "sentiment_map = {\n",
    "    # French / variants meaning Positive\n",
    "    \"Positive\": \"positive\",\n",
    "    \"Positf\": \"positive\",\n",
    "    \"Positidf\": \"positive\",\n",
    "    \"Positiveouneutre\": \"positive\",\n",
    "    \"Positiveetnaturelle\": \"positive\",\n",
    "    \"Trespositive\": \"positive\",\n",
    "    \"Trèspositive\": \"positive\",\n",
    "\n",
    "    # French / variants meaning Negative\n",
    "    \"Negative\": \"negative\",\n",
    "    \"Négative\": \"negative\",\n",
    "    \"Tresnegative\": \"negative\",\n",
    "    \"Trèsnegative\": \"negative\",\n",
    "\n",
    "    # Neutral / misspelled variants\n",
    "    \"Neutre\": \"neutral\",\n",
    "    \"Neutrre\": \"neutral\",\n",
    "    \"Neuitre\": \"neutral\",\n",
    "\n",
    "    # Ambiguous terms\n",
    "    \"Ambivalent\": \"neutral\",   # interpret ambivalent as neutral\n",
    "}\n",
    "\n",
    "df_lexicon['Sentiment'] = df_lexicon['Sentiment'].map(sentiment_map)\n",
    "df_lexicon.to_excel('./lexicon_dataset/expanded_lexicon_cleaned.xlsx', index=False)\n",
    "print(df_lexicon[\"Sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645e902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre cleaning dataset length:  6632\n",
      "translated populace to bevolking\n",
      "Post cleaning dataset length:  6451\n"
     ]
    }
   ],
   "source": [
    "def tokenize_text(text):\n",
    "    text = text.translate(str.maketrans('', '', '()[]{}1234567890.?!')).lower().split('\\t')\n",
    "    return text\n",
    "\n",
    "if stopwords.has_lang(\"zu\"):\n",
    "    zulu_stopwords = stopwords.stopwords(\"zu\") # Used to filter out common words\n",
    "else:\n",
    "    print(\"No stopwords found for Zulu\")\n",
    "\n",
    "df_lexicon_clean = pd.read_excel('./lexicon_dataset/expanded_lexicon_cleaned.xlsx')\n",
    "print('Pre cleaning dataset length: ', len(df_lexicon_clean))\n",
    "columns = []\n",
    "for col in df_lexicon_clean.columns:\n",
    "    if col != 'Score':\n",
    "        columns.append(col)\n",
    "\n",
    "for col in df_lexicon_clean.columns:\n",
    "    if df_lexicon_clean[col].dtype == 'object':\n",
    "        df_lexicon_clean[col] = df_lexicon_clean[col].str.lower()\n",
    "        \n",
    "df_lexicon_clean[columns] = df_lexicon_clean[columns].replace(np.nan, None)\n",
    "           \n",
    "lang_key = {\n",
    "    \"English\": \"en\",\n",
    "    \"Zulu\": \"zu\",\n",
    "    \"Afrikaans\": \"af\",\n",
    "    \"Sepedi\": \"nso\",\n",
    "    \"Xhosa\": \"xh\",\n",
    "    \"Shona\": \"sn\"\n",
    "}\n",
    "translator = Translator()\n",
    "def retranslator(index):\n",
    "    for col in [\"English\",\"Zulu\",\"Afrikaans\",\"Sepedi\",\"Xhosa\",\"Shona\"]:\n",
    "        if df_lexicon_clean.at[index, col] is None:\n",
    "            detect = translator.detect(df_lexicon_clean.at[index, 'French'])\n",
    "            if detect.lang != 'fr':\n",
    "                try:\n",
    "                    translated = translator.translate(df_lexicon_clean.at[index, 'French'], src=detect.lang, dest=lang_key[col])\n",
    "                    df_lexicon_clean.at[index, col] = translated.text\n",
    "                    print(f'translated {df_lexicon_clean.at[index, 'French']} to {translated.text}')\n",
    "                except:\n",
    "                    print(f'could not translate {df_lexicon_clean.at[index, 'French']} to {col}')\n",
    "                    continue\n",
    "\n",
    "for index, row in df_lexicon_clean.iterrows():\n",
    "    retranslator(index)\n",
    "\n",
    "for index, row in df_lexicon_clean.iterrows():\n",
    "    if row['Zulu'] in zulu_stopwords:\n",
    "        df_lexicon_clean = df_lexicon_clean.drop(index)\n",
    "\n",
    "newSentiments = []\n",
    "for index, row in df_lexicon_clean.iterrows():   \n",
    "    if row['Score'] > 0.5:\n",
    "        newSentiments.append('postive')\n",
    "    elif row['Score'] < -0.5:\n",
    "        newSentiments.append('negative')\n",
    "    else:\n",
    "        newSentiments.append('neutral')\n",
    "\n",
    "df_lexicon_clean['Sentiment'] = newSentiments\n",
    "df_lexicon_clean = df_lexicon_clean.drop_duplicates()\n",
    "print('Post cleaning dataset length: ', len(df_lexicon_clean))\n",
    "df_lexicon_clean.to_excel('./lexicon_dataset/expanded_lexicon_cleaned.xlsx', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "21c65b52-094d-4eb9-95a7-be6a054d36fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text samples from corpus:  4640\n",
      "            isiZulu\n",
      "0          <LINE 1>\n",
      "1  Abacwaningi\\tN02\n",
      "2          bathi\\tV\n",
      "3      ukujezisa\\tV\n",
      "4   ngokushaya\\tADV\n"
     ]
    }
   ],
   "source": [
    "# Extracting different text features from the corpus extracted from SADII of news articles in isiZulu\n",
    "file = open('SADII-Ext.Caps.POS.2024-01-31.zu.txt', 'r', encoding='utf-8')\n",
    "lines = file.read()\n",
    "lines = lines.splitlines()\n",
    "file.close()\n",
    "    \n",
    "df_corpus = pd.DataFrame(lines, columns=['isiZulu'])\n",
    "df_corpus['isiZulu'] = df_corpus['isiZulu'].str.strip()\n",
    "\n",
    "print(\"Total text samples from corpus: \", len(df_corpus))\n",
    "print(df_corpus.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fc448560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text samples:  465\n",
      "                                             isiZulu\n",
      "0  abacwaningi bathi ukujezisa ngokushaya noma ng...\n",
      "1  abafundi abasebancane kakhulu bona bangakuthok...\n",
      "2                                       abangaphoqwa\n",
      "3  abantu abaningi bayaluthokozela lolu hlelo kwa...\n",
      "4  abantu abasha bakhala ngemfundo yamahhala kany...\n"
     ]
    }
   ],
   "source": [
    "# Cleaning and Tokenization\n",
    "df_corpus_text = pd.DataFrame(columns=['isiZulu'])\n",
    "\n",
    "# Reverse engineering the text samples based on <line> tags\n",
    "text = ''\n",
    "for corpus_text in df_corpus['isiZulu']:\n",
    "    if '<line' in corpus_text.lower():\n",
    "        if text:\n",
    "            text = text.strip().replace('\"', '')\n",
    "            df_corpus_text.loc[len(df_corpus_text)] = text\n",
    "            \n",
    "        text = ''\n",
    "        continue\n",
    "    \n",
    "    tokens = tokenize_text(corpus_text)\n",
    "    text += tokens[0] + ' '\n",
    "\n",
    "print(\"Total text samples: \", len(df_corpus_text))\n",
    "print(df_corpus_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e3feba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus translation in progress\n",
      "                                             isiZulu  \\\n",
      "0  abacwaningi bathi ukujezisa ngokushaya noma ng...   \n",
      "1  abafundi abasebancane kakhulu bona bangakuthok...   \n",
      "2                                       abangaphoqwa   \n",
      "3  abantu abaningi bayaluthokozela lolu hlelo kwa...   \n",
      "4  abantu abasha bakhala ngemfundo yamahhala kany...   \n",
      "\n",
      "                                             English Sentiment  \n",
      "0  researchers say that punishing by beating, no ...  Negative  \n",
      "1  Younger readers can enjoy reading texts with l...  Positive  \n",
      "2                               who cannot be forced  Positive  \n",
      "3  Many people enjoy this program because even a ...  Positive  \n",
      "4  young people are complaining about free educat...  Negative  \n"
     ]
    }
   ],
   "source": [
    "english_text = []\n",
    "sentiment_result = []\n",
    "\n",
    "print('Corpus translation in progress')\n",
    "for sentence in df_corpus_text['isiZulu']:\n",
    "    translated_text = GoogleTranslator(source='auto', target='en').translate(sentence)\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment_dict = analyzer.polarity_scores(translated_text)\n",
    "    \n",
    "    english_text.append(translated_text)\n",
    "    if sentiment_dict['compound'] >= 0.05:\n",
    "        sentiment_result.append('Positive')     \n",
    "    elif sentiment_dict['compound'] <= - 0.05:\n",
    "        sentiment_result.append('Negative')   \n",
    "    else:\n",
    "        sentiment_result.append('Neutral')   \n",
    "\n",
    "df_corpus_text['English'] = english_text\n",
    "df_corpus_text['Sentiment'] = sentiment_result\n",
    "print(df_corpus_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f636864f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pre-cleansed samples:  465\n",
      "Number of post-cleansed samples:  465\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of pre-cleansed samples: \", len(df_corpus_text))\n",
    "# Clean untranslated text samples\n",
    "for index, row in df_corpus_text.iterrows():\n",
    "    detect = translator.detect(row['English'])\n",
    "    if detect.lang != 'en':\n",
    "        try:\n",
    "            translated = translator.translate(row['English'], src=detect.lang, dest='en')\n",
    "            df_corpus_text.at[index, 'English'] = translated.text\n",
    "        except:\n",
    "            df_corpus_text.drop(index, inplace=True)\n",
    "\n",
    "print(\"Number of post-cleansed samples: \", len(df_corpus_text))\n",
    "df_corpus_text.to_csv('./corpus_datasets/Zulu_to_English_Corpus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa18bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens for PMI (after removing stopwords): 5686\n",
      "Top positive candidate words:\n",
      "              word   PMI_Pos   PMI_Neg  PMI_Diff\n",
      "2000         wakhe  0.585026 -1.425497  2.010523\n",
      "80     zokuxhumana  0.585026 -1.425497  2.010523\n",
      "1195       iqiniso  0.906954 -0.840535  1.747489\n",
      "778         ithuba  0.906954 -0.840535  1.747489\n",
      "384         ngakho  0.684562 -1.062927  1.747489\n",
      "132       imidlalo  0.684562 -1.062927  1.747489\n",
      "79    ezinkundleni  0.684562 -1.062927  1.747489\n",
      "904          ukuze  0.453781 -1.194172  1.647953\n",
      "509         impilo  0.585026 -0.840535  1.425561\n",
      "585         sifuna  0.585026 -0.840535  1.425561\n",
      "505         phansi  0.585026 -0.840535  1.425561\n",
      "426           nabo  0.169988 -1.255572  1.425561\n",
      "683          isimo  0.848060 -0.577501  1.425561\n",
      "237           kulo  0.362634 -1.062927  1.425561\n",
      "774        uthando  0.848060 -0.577501  1.425561\n",
      "444         ezinye  0.848060 -0.577501  1.425561\n",
      "447          ngami  0.848060 -0.577501  1.425561\n",
      "161          ngayo  0.381493 -0.918537  1.300030\n",
      "3395    emicimbini  1.169988  0.000000  1.169988\n",
      "3396   bekhuthazwa  1.169988  0.000000  1.169988\n",
      "\n",
      "Top negative candidate words:\n",
      "                 word   PMI_Pos   PMI_Neg  PMI_Diff\n",
      "1053             kabi -1.830012  1.551782 -3.381794\n",
      "1384            nzima -1.151940  1.422499 -2.574439\n",
      "646            akekho -1.151940  1.422499 -2.574439\n",
      "55             ingane -1.999937  0.574503 -2.574439\n",
      "128            impela -0.830012  1.329390 -2.159402\n",
      "815             yakhe -0.830012  1.066356 -1.896367\n",
      "306             manje -0.945489  0.851343 -1.796832\n",
      "3343            ucele  0.000000  1.744428 -1.744428\n",
      "3380             impi  0.000000  1.744428 -1.744428\n",
      "3173  namaphephandaba  0.000000  1.744428 -1.744428\n",
      "26        ngingathini  0.000000  1.744428 -1.744428\n",
      "28          kuyaphoxa  0.000000  1.744428 -1.744428\n",
      "29            ushaywe  0.000000  1.744428 -1.744428\n",
      "30             ngento  0.000000  1.744428 -1.744428\n",
      "31              okade  0.000000  1.744428 -1.744428\n",
      "32         uyiqeqesha  0.000000  1.744428 -1.744428\n",
      "33             isonto  0.000000  1.744428 -1.744428\n",
      "3336          inzondo  0.000000  1.744428 -1.744428\n",
      "61            angithi  0.000000  1.744428 -1.744428\n",
      "64              uqala  0.000000  1.744428 -1.744428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\vanma\\AppData\\Local\\Temp\\ipykernel_5760\\3890579250.py:6: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  df_lexicon = pd.read_csv('.\\corpus_datasets\\Zulu_to_English_Corpus.csv')\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "\n",
    "df_lexicon = pd.read_csv('.\\corpus_datasets\\Zulu_to_English_Corpus.csv')\n",
    "#need to expand stop words list\n",
    "zulu_stopwords = set([\n",
    "    'nokuthi', 'yokuthi', 'kanti', 'futhi', 'ke', 'na', 'kakhulu',\n",
    "    'uma', 'ku', 'ngokuthi', 'lokhu', 'konke', 'zonke'\n",
    "]) \n",
    "\n",
    "\n",
    "df_words = []\n",
    "for idx, row in df_lexicon.iterrows():\n",
    "    words = row['isiZulu'].lower().split()\n",
    "    for w in words:\n",
    "        # Remove punctuation\n",
    "        w = w.strip('.,!?;\"()[]{}')\n",
    "        # Skip empty strings and stopwords\n",
    "        if w and w not in zulu_stopwords:\n",
    "            df_words.append({'tokens': w, 'label': row['Sentiment'].lower()})\n",
    "\n",
    "df_tokens_labeled = pd.DataFrame(df_words)\n",
    "\n",
    "print(f\"Total tokens for PMI (after removing stopwords): {len(df_tokens_labeled)}\")\n",
    "\n",
    "pos_tokens = df_tokens_labeled[df_tokens_labeled['label'] == 'positive']['tokens'].tolist()\n",
    "neg_tokens = df_tokens_labeled[df_tokens_labeled['label'] == 'negative']['tokens'].tolist()\n",
    "\n",
    "pos_counts = Counter(pos_tokens)\n",
    "neg_counts = Counter(neg_tokens)\n",
    "all_counts = Counter(df_tokens_labeled['tokens'])\n",
    "\n",
    "total_pos = sum(pos_counts.values())\n",
    "total_neg = sum(neg_counts.values())\n",
    "total_all = sum(all_counts.values())\n",
    "\n",
    "\n",
    "pmi_data = []\n",
    "for word in all_counts:\n",
    "    p_word = all_counts[word] / total_all\n",
    "    pmi_pos = math.log2((pos_counts[word]/total_pos)/p_word) if word in pos_counts else 0\n",
    "    pmi_neg = math.log2((neg_counts[word]/total_neg)/p_word) if word in neg_counts else 0\n",
    "    pmi_diff = pmi_pos - pmi_neg\n",
    "    pmi_data.append((word, pmi_pos, pmi_neg, pmi_diff))\n",
    "\n",
    "df_pmi = pd.DataFrame(pmi_data, columns=['word', 'PMI_Pos', 'PMI_Neg', 'PMI_Diff'])\n",
    "\n",
    "positive_candidates = df_pmi[df_pmi['PMI_Diff'] > 1].sort_values(by='PMI_Diff', ascending=False)\n",
    "negative_candidates = df_pmi[df_pmi['PMI_Diff'] < -1].sort_values(by='PMI_Diff', ascending=True)\n",
    "\n",
    "print(\"Top positive candidate words:\")\n",
    "print(positive_candidates.head(20))\n",
    "\n",
    "print(\"\\nTop negative candidate words:\")\n",
    "print(negative_candidates.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
