{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40f823ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\116su\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\116su\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add additional imports under here\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import stopwordsiso as stopwords\n",
    "from deep_translator import GoogleTranslator\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from googletrans import Translator\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import math\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "from google import genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab760bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CILUBA', 'French', 'Score', 'Sentiment', 'Nature']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CILUBA</th>\n",
       "      <th>French</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Nature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Akaja</td>\n",
       "      <td>Arrange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akajilula</td>\n",
       "      <td>Rearrange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akula</td>\n",
       "      <td>Parle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akulula</td>\n",
       "      <td>Reparle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aluja</td>\n",
       "      <td>Remet</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CILUBA     French  Score Sentiment Nature\n",
       "0      Akaja    Arrange    1.0   Positif  Verbe\n",
       "1  Akajilula  Rearrange    1.0   Positif  Verbe\n",
       "2      Akula      Parle    2.0   Positif  Verbe\n",
       "3    Akulula    Reparle    2.0   Positif  Verbe\n",
       "4      Aluja      Remet    3.0   Positif  Verbe"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading\n",
    "df = pd.read_excel(\"lexicon_6000 words.xlsx\")\n",
    "\n",
    "#keep a copy of the original columns\n",
    "original_Cols = df.columns.tolist()\n",
    "print(original_Cols)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a9c1ac-1778-4554-84a3-c539b92f62e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n",
      "dataset size: 6963\n",
      "new dataset size: 6646\n"
     ]
    }
   ],
   "source": [
    "dup_Count = df.duplicated().sum()\n",
    "print(dup_Count)\n",
    "\n",
    "if dup_Count > 0:\n",
    "    print(\"dataset size:\", len(df)) \n",
    "    df = df.drop_duplicates()\n",
    "    print(\"new dataset size:\", len(df))\n",
    "\n",
    "#taking away any duplication/ spacing errors\n",
    "col_Strings = df.select_dtypes(include=['object']).columns\n",
    "for col in col_Strings:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "    df[col] = df[col].str.replace(r'\\s+','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b7927d-ca65-4ad1-9706-c1fe52fe398d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CILUBA</th>\n",
       "      <th>French</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Nature</th>\n",
       "      <th>English</th>\n",
       "      <th>Zulu</th>\n",
       "      <th>Afrikaans</th>\n",
       "      <th>Sepedi</th>\n",
       "      <th>Xhosa</th>\n",
       "      <th>Shona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Akaja</td>\n",
       "      <td>Arrange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akajilula</td>\n",
       "      <td>Rearrange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akula</td>\n",
       "      <td>Parle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akulula</td>\n",
       "      <td>Reparle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aluja</td>\n",
       "      <td>Remet</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CILUBA     French  Score Sentiment Nature  English  Zulu  Afrikaans  \\\n",
       "0      Akaja    Arrange    1.0   Positif  Verbe      NaN   NaN        NaN   \n",
       "1  Akajilula  Rearrange    1.0   Positif  Verbe      NaN   NaN        NaN   \n",
       "2      Akula      Parle    2.0   Positif  Verbe      NaN   NaN        NaN   \n",
       "3    Akulula    Reparle    2.0   Positif  Verbe      NaN   NaN        NaN   \n",
       "4      Aluja      Remet    3.0   Positif  Verbe      NaN   NaN        NaN   \n",
       "\n",
       "   Sepedi  Xhosa  Shona  \n",
       "0     NaN    NaN    NaN  \n",
       "1     NaN    NaN    NaN  \n",
       "2     NaN    NaN    NaN  \n",
       "3     NaN    NaN    NaN  \n",
       "4     NaN    NaN    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_Languages = [\"English\", \"Zulu\", \"Afrikaans\", \"Sepedi\", \"Xhosa\", \"Shona\"]\n",
    "\n",
    "for lang in new_Languages:\n",
    "    if lang not in df.columns:\n",
    "        df[lang] = np.nan\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00be8d77-8f9e-44e4-b9e6-af7fdbdd00c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate_French_To_English(text):\n",
    "    if pd.isna(text) or text.strip==\"\":\n",
    "        return np.man\n",
    "    try:\n",
    "        return GoogleTranslator(source='fr', target='en').translate(text)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def translate_English_To_Language(text, language_Code):\n",
    "    if pd.isna(text) or text.strip()==\"\":\n",
    "        return np.man\n",
    "    try:\n",
    "        return GoogleTranslator(source=\"en\", target=language_Code).translate(text)\n",
    "    except Exception:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e503ceee-7173-41f4-9397-af2025888e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df[\"English\"] = df[\"French\"].progress_apply(translate_French_To_English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e64bcf-515b-4e3a-8f1a-e18e60627d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors occured: 0\n",
      "Unique English words: 3864\n"
     ]
    }
   ],
   "source": [
    "print(\"Errors occured:\", df[\"English\"].isna().sum())\n",
    "print(\"Unique English words:\", df[\"English\"].nunique(dropna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428536c-451a-4986-9438-4310d8ae9eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6632/6632 [2:25:27<00:00,  1.32s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6632/6632 [2:15:14<00:00,  1.22s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6632/6632 [2:04:38<00:00,  1.13s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6632/6632 [2:26:53<00:00,  1.33s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6632/6632 [2:19:04<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "language_Code = {\"Zulu\":\"zu\", \"Afrikaans\":\"af\", \"Sepedi\":\"nso\", \"Xhosa\":\"xh\", \"Shona\":\"sn\"}\n",
    "\n",
    "for lang, code in language_Code.items():\n",
    "    df[lang] = df[\"English\"].progress_apply(lambda x: translate_English_To_Language(x, code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471082a0-bace-4112-b867-736dfd4bf75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CILUBA</th>\n",
       "      <th>French</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Nature</th>\n",
       "      <th>English</th>\n",
       "      <th>Zulu</th>\n",
       "      <th>Afrikaans</th>\n",
       "      <th>Sepedi</th>\n",
       "      <th>Xhosa</th>\n",
       "      <th>Shona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Akaja</td>\n",
       "      <td>Arrange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Arrange</td>\n",
       "      <td>Hlela</td>\n",
       "      <td>Reël</td>\n",
       "      <td>Beakanya</td>\n",
       "      <td>Cwangcisa</td>\n",
       "      <td>Ronga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akajilula</td>\n",
       "      <td>Rearrange</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Rear range</td>\n",
       "      <td>Ibanga langemuva</td>\n",
       "      <td>Grootafstand</td>\n",
       "      <td>Range ya ka morao .</td>\n",
       "      <td>Uluhlu lwangasemva</td>\n",
       "      <td>Kumashure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akula</td>\n",
       "      <td>Parle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Speak</td>\n",
       "      <td>Khuluma</td>\n",
       "      <td>Praat</td>\n",
       "      <td>Bolela</td>\n",
       "      <td>Thetha</td>\n",
       "      <td>Taura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akulula</td>\n",
       "      <td>Reparle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Speak again</td>\n",
       "      <td>Khuluma futhi</td>\n",
       "      <td>Praat weer</td>\n",
       "      <td>Bolela gape .</td>\n",
       "      <td>Thetha kwakhona</td>\n",
       "      <td>Taura zvakare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aluja</td>\n",
       "      <td>Remet</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Hands over</td>\n",
       "      <td>Izandla ngaphezulu</td>\n",
       "      <td>Hande om</td>\n",
       "      <td>diatla godimo ga .</td>\n",
       "      <td>Izandla ngaphezulu</td>\n",
       "      <td>Maoko pamusoro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amba</td>\n",
       "      <td>Dis</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Say</td>\n",
       "      <td>Khuluma</td>\n",
       "      <td>Sê</td>\n",
       "      <td>Bolela</td>\n",
       "      <td>Yithi</td>\n",
       "      <td>Taura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ambakaja</td>\n",
       "      <td>Supperpose</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Suppose</td>\n",
       "      <td>Cabanga</td>\n",
       "      <td>Veronderstel</td>\n",
       "      <td>Nagana</td>\n",
       "      <td>Cinga</td>\n",
       "      <td>Ngatitii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ambula</td>\n",
       "      <td>Ramasse</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Pick up</td>\n",
       "      <td>Phakamisa</td>\n",
       "      <td>Optel</td>\n",
       "      <td>Topa</td>\n",
       "      <td>Phakamisa</td>\n",
       "      <td>Nhonga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ambuluja</td>\n",
       "      <td>Depeche</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Depeche</td>\n",
       "      <td>I-depeche</td>\n",
       "      <td>Depeche</td>\n",
       "      <td>Depeche .</td>\n",
       "      <td>I-dope</td>\n",
       "      <td>Zvinorevache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ambulula</td>\n",
       "      <td>Repete</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Repeated</td>\n",
       "      <td>-Phindaphiwe</td>\n",
       "      <td>Herhaal</td>\n",
       "      <td>pheta-pheta .</td>\n",
       "      <td>Iphindaphindwe</td>\n",
       "      <td>Kudzokororwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Andamuna</td>\n",
       "      <td>Repond</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Answers</td>\n",
       "      <td>Ukuphendula</td>\n",
       "      <td>Antwoorde</td>\n",
       "      <td>Dikarabo .</td>\n",
       "      <td>Iimpendulo</td>\n",
       "      <td>Mhinduro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Angata</td>\n",
       "      <td>Prend</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Takes</td>\n",
       "      <td>Izakahlela</td>\n",
       "      <td>Neem</td>\n",
       "      <td>E tšea .</td>\n",
       "      <td>Ithatha</td>\n",
       "      <td>Zvinotora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Angatulula</td>\n",
       "      <td>Reprend</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Resume</td>\n",
       "      <td>Qalela phansi</td>\n",
       "      <td>Hervat</td>\n",
       "      <td>Thomološa</td>\n",
       "      <td>Phinda Uqalele</td>\n",
       "      <td>Tangazve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bilamba</td>\n",
       "      <td>Habits</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Mot</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>Izingubo</td>\n",
       "      <td>Klere</td>\n",
       "      <td>Diaparo</td>\n",
       "      <td>Iimpahla</td>\n",
       "      <td>Zvipfeko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bilela</td>\n",
       "      <td>Blague</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Mot</td>\n",
       "      <td>Joke</td>\n",
       "      <td>Ihlaya</td>\n",
       "      <td>Grap</td>\n",
       "      <td>Metlae</td>\n",
       "      <td>Hlekisa</td>\n",
       "      <td>Joke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Biluatu</td>\n",
       "      <td>Vetements</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Mot</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>Izingubo</td>\n",
       "      <td>Klere</td>\n",
       "      <td>Diaparo</td>\n",
       "      <td>Iimpahla</td>\n",
       "      <td>Zvipfeko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Binsonji</td>\n",
       "      <td>Larmes</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Mot</td>\n",
       "      <td>Tears</td>\n",
       "      <td>Izinyembekathi</td>\n",
       "      <td>Trane</td>\n",
       "      <td>Megokgo</td>\n",
       "      <td>Iinyembezi</td>\n",
       "      <td>Misodzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Buela</td>\n",
       "      <td>Entre</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Verbe</td>\n",
       "      <td>Between</td>\n",
       "      <td>Ngaphakathi</td>\n",
       "      <td>Tussen</td>\n",
       "      <td>Magareng</td>\n",
       "      <td>Phakathi</td>\n",
       "      <td>Pakati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bukenka</td>\n",
       "      <td>Lumiere</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Mot</td>\n",
       "      <td>Light</td>\n",
       "      <td>-Mhlophe</td>\n",
       "      <td>Lig</td>\n",
       "      <td>Seetša</td>\n",
       "      <td>Ukukhanya</td>\n",
       "      <td>Chiedza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Buloba</td>\n",
       "      <td>Terre</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Mot</td>\n",
       "      <td>Earth</td>\n",
       "      <td>Inhlabathi</td>\n",
       "      <td>Aarde</td>\n",
       "      <td>Lefase</td>\n",
       "      <td>Umhlaba</td>\n",
       "      <td>Pasi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CILUBA      French  Score Sentiment Nature      English  \\\n",
       "0        Akaja     Arrange    1.0   Positif  Verbe      Arrange   \n",
       "1    Akajilula   Rearrange    1.0   Positif  Verbe   Rear range   \n",
       "2        Akula       Parle    2.0   Positif  Verbe        Speak   \n",
       "3      Akulula     Reparle    2.0   Positif  Verbe  Speak again   \n",
       "4        Aluja       Remet    3.0   Positif  Verbe   Hands over   \n",
       "5         Amba         Dis    3.0   Positif  Verbe          Say   \n",
       "6     Ambakaja  Supperpose    3.0   Positif  Verbe      Suppose   \n",
       "7       Ambula     Ramasse    4.0   Positif  Verbe      Pick up   \n",
       "8     Ambuluja     Depeche    4.0   Positif  Verbe      Depeche   \n",
       "9     Ambulula      Repete    9.0   Positif  Verbe     Repeated   \n",
       "10    Andamuna      Repond    9.0   Positif  Verbe      Answers   \n",
       "11      Angata       Prend    9.0   Positif  Verbe        Takes   \n",
       "12  Angatulula     Reprend    9.0   Positif  Verbe       Resume   \n",
       "13     Bilamba      Habits    8.0   Positif    Mot      Clothes   \n",
       "14      Bilela      Blague    8.0   Positif    Mot         Joke   \n",
       "15     Biluatu   Vetements   -1.0   Negatif    Mot      Clothes   \n",
       "16    Binsonji      Larmes    7.0   Positif    Mot        Tears   \n",
       "17       Buela       Entre    7.0   Positif  Verbe      Between   \n",
       "18     Bukenka     Lumiere    7.0   Positif    Mot        Light   \n",
       "19      Buloba       Terre   -1.0   Negatif    Mot        Earth   \n",
       "\n",
       "                  Zulu     Afrikaans               Sepedi               Xhosa  \\\n",
       "0                Hlela          Reël             Beakanya           Cwangcisa   \n",
       "1     Ibanga langemuva  Grootafstand  Range ya ka morao .  Uluhlu lwangasemva   \n",
       "2              Khuluma         Praat               Bolela              Thetha   \n",
       "3        Khuluma futhi    Praat weer        Bolela gape .     Thetha kwakhona   \n",
       "4   Izandla ngaphezulu      Hande om   diatla godimo ga .  Izandla ngaphezulu   \n",
       "5              Khuluma            Sê               Bolela               Yithi   \n",
       "6              Cabanga  Veronderstel               Nagana               Cinga   \n",
       "7            Phakamisa         Optel                 Topa           Phakamisa   \n",
       "8            I-depeche       Depeche            Depeche .              I-dope   \n",
       "9         -Phindaphiwe       Herhaal        pheta-pheta .      Iphindaphindwe   \n",
       "10         Ukuphendula     Antwoorde           Dikarabo .          Iimpendulo   \n",
       "11          Izakahlela          Neem             E tšea .             Ithatha   \n",
       "12       Qalela phansi        Hervat            Thomološa      Phinda Uqalele   \n",
       "13            Izingubo         Klere              Diaparo            Iimpahla   \n",
       "14              Ihlaya          Grap               Metlae             Hlekisa   \n",
       "15            Izingubo         Klere              Diaparo            Iimpahla   \n",
       "16      Izinyembekathi         Trane              Megokgo          Iinyembezi   \n",
       "17         Ngaphakathi        Tussen             Magareng            Phakathi   \n",
       "18            -Mhlophe           Lig               Seetša           Ukukhanya   \n",
       "19          Inhlabathi         Aarde               Lefase             Umhlaba   \n",
       "\n",
       "             Shona  \n",
       "0            Ronga  \n",
       "1        Kumashure  \n",
       "2            Taura  \n",
       "3    Taura zvakare  \n",
       "4   Maoko pamusoro  \n",
       "5            Taura  \n",
       "6         Ngatitii  \n",
       "7           Nhonga  \n",
       "8     Zvinorevache  \n",
       "9     Kudzokororwa  \n",
       "10        Mhinduro  \n",
       "11       Zvinotora  \n",
       "12        Tangazve  \n",
       "13        Zvipfeko  \n",
       "14            Joke  \n",
       "15        Zvipfeko  \n",
       "16         Misodzi  \n",
       "17          Pakati  \n",
       "18         Chiedza  \n",
       "19            Pasi  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c92af-2705-4fba-8f51-5103ffc7ace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zulu: missing 1\n",
      "Afrikaans: missing 0\n",
      "Sepedi: missing 0\n",
      "Xhosa: missing 1\n",
      "Shona: missing 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "English      3864\n",
       "Zulu         3513\n",
       "Afrikaans    3647\n",
       "Sepedi       3376\n",
       "Xhosa        3367\n",
       "Shona        3156\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing translations (NaN)\n",
    "for lang in [\"Zulu\",\"Afrikaans\",\"Sepedi\",\"Xhosa\",\"Shona\"]:\n",
    "    print(f\"{lang}: missing {df[lang].isna().sum()}\")\n",
    "\n",
    "# unique counter\n",
    "df[[\"English\",\"Zulu\",\"Afrikaans\",\"Sepedi\",\"Xhosa\",\"Shona\"]].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b6b43ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "positive    4361\n",
      "neutral     1121\n",
      "negative    1116\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_lexicon = pd.read_excel('./lexicon_dataset/expanded_lexicon.xlsx')\n",
    "\n",
    "sentiment_map = {\n",
    "    # French / variants meaning Positive\n",
    "    \"Positive\": \"positive\",\n",
    "    \"Positf\": \"positive\",\n",
    "    \"Positidf\": \"positive\",\n",
    "    \"Positiveouneutre\": \"positive\",\n",
    "    \"Positiveetnaturelle\": \"positive\",\n",
    "    \"Trespositive\": \"positive\",\n",
    "    \"Trèspositive\": \"positive\",\n",
    "\n",
    "    # French / variants meaning Negative\n",
    "    \"Negative\": \"negative\",\n",
    "    \"Négative\": \"negative\",\n",
    "    \"Tresnegative\": \"negative\",\n",
    "    \"Trèsnegative\": \"negative\",\n",
    "\n",
    "    # Neutral / misspelled variants\n",
    "    \"Neutre\": \"neutral\",\n",
    "    \"Neutrre\": \"neutral\",\n",
    "    \"Neuitre\": \"neutral\",\n",
    "\n",
    "    # Ambiguous terms\n",
    "    \"Ambivalent\": \"neutral\",   # interpret ambivalent as neutral\n",
    "}\n",
    "\n",
    "df_lexicon['Sentiment'] = df_lexicon['Sentiment'].map(sentiment_map)\n",
    "df_lexicon.to_excel('./lexicon_dataset/expanded_lexicon_cleaned.xlsx', index=False)\n",
    "print(df_lexicon[\"Sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7645e902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre cleaning dataset length:  6632\n",
      "could not translate populace to Afrikaans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\116su\\AppData\\Local\\Temp\\ipykernel_4384\\2323276469.py:61: RuntimeWarning: coroutine 'Translator.translate' was never awaited\n",
      "  await retranslator(index)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post cleaning dataset length:  5902\n"
     ]
    }
   ],
   "source": [
    "def tokenize_text(text):\n",
    "    text = text.translate(str.maketrans('', '', '()[]{}1234567890.?!')).lower().split('\\t')\n",
    "    return text\n",
    "\n",
    "if stopwords.has_lang(\"zu\"):\n",
    "    zulu_stopwords = stopwords.stopwords(\"zu\") # Used to filter out common words\n",
    "else:\n",
    "    print(\"No stopwords found for Zulu\")\n",
    "    \n",
    "if stopwords.has_lang(\"en\"):\n",
    "    english_stopwords = stopwords.stopwords(\"en\") # Used to filter out common words\n",
    "else:\n",
    "    print(\"No stopwords found for English\")\n",
    "\n",
    "df_lexicon_clean = pd.read_excel('./lexicon_dataset/expanded_lexicon_cleaned.xlsx')\n",
    "print('Pre cleaning dataset length: ', len(df_lexicon_clean))\n",
    "columns = []\n",
    "for col in df_lexicon_clean.columns:\n",
    "    if col != 'Score':\n",
    "        columns.append(col)\n",
    "\n",
    "for col in df_lexicon_clean.columns:\n",
    "    if df_lexicon_clean[col].dtype == 'object':\n",
    "        df_lexicon_clean[col] = df_lexicon_clean[col].str.lower()\n",
    "        \n",
    "df_lexicon_clean[columns] = df_lexicon_clean[columns].replace(np.nan, None)\n",
    "           \n",
    "lang_key = {\n",
    "    \"English\": \"en\",\n",
    "    \"Zulu\": \"zu\",\n",
    "    \"Afrikaans\": \"af\",\n",
    "    \"Sepedi\": \"nso\",\n",
    "    \"Xhosa\": \"xh\",\n",
    "    \"Shona\": \"sn\"\n",
    "}\n",
    "\n",
    "def retokenize_text(text):\n",
    "    newtext = ''\n",
    "    tokens = text.split(' ')\n",
    "    tokens = [token if token not in english_stopwords else '' for token in tokens]\n",
    "    for token in tokens:\n",
    "       newtext += token\n",
    "    return newtext\n",
    "\n",
    "translator = Translator()\n",
    "async def retranslator(index):\n",
    "    for col in [\"English\",\"Zulu\",\"Afrikaans\",\"Sepedi\",\"Xhosa\",\"Shona\"]:\n",
    "        if df_lexicon_clean.at[index, col] is None:\n",
    "            detect = await translator.detect(df_lexicon_clean.at[index, 'French'])\n",
    "            if detect.lang != 'fr':\n",
    "                try:\n",
    "                    translated = translator.translate(df_lexicon_clean.at[index, 'French'], src=detect.lang, dest=lang_key[col])\n",
    "                    df_lexicon_clean.at[index, col] = translated.text\n",
    "                    print(f'translated {df_lexicon_clean.at[index, 'French']} to {translated.text}')\n",
    "                except:\n",
    "                    print(f'could not translate {df_lexicon_clean.at[index, 'French']} to {col}')\n",
    "                    continue\n",
    "\n",
    "# Translate null translated columns\n",
    "for index, row in df_lexicon_clean.iterrows():\n",
    "    await retranslator(index)\n",
    "\n",
    "# Dropping stop words of zulu text\n",
    "for index, row in df_lexicon_clean.iterrows():\n",
    "    if row['Zulu'] in zulu_stopwords:\n",
    "        df_lexicon_clean = df_lexicon_clean.drop(index)\n",
    "        continue\n",
    "    \n",
    "    df_lexicon_clean.at[index, 'English'] = retokenize_text(row['English'])\n",
    "    if row['English'] in english_stopwords:\n",
    "        df_lexicon_clean = df_lexicon_clean.drop(index)\n",
    "\n",
    "newSentiments = []\n",
    "for index, row in df_lexicon_clean.iterrows():   \n",
    "    if row['Score'] > 0.5:\n",
    "        newSentiments.append('postive')\n",
    "    elif row['Score'] < -0.5:\n",
    "        newSentiments.append('negative')\n",
    "    else:\n",
    "        newSentiments.append('neutral')\n",
    "\n",
    "df_lexicon_clean['Sentiment'] = newSentiments\n",
    "df_lexicon_clean = df_lexicon_clean.drop_duplicates()\n",
    "print('Post cleaning dataset length: ', len(df_lexicon_clean))\n",
    "df_lexicon_clean.to_excel('./lexicon_dataset/expanded_lexicon_cleaned.xlsx', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8a88f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french duplicates:  French\n",
      "False    3359\n",
      "True     2543\n",
      "Name: count, dtype: int64\n",
      "lemmatizing...\n",
      "post lemmatizing french duplicates:  French\n",
      "False    3355\n",
      "True     2535\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Lemmating and re-runing pos taging in using french words to reduce ambiguity \n",
    "lemmatizer = FrenchLefffLemmatizer()\n",
    "\n",
    "print('french duplicates: ', df_lexicon_clean['French'].duplicated().value_counts())\n",
    "print('lemmatizing...')\n",
    "for index, row in df_lexicon_clean.iterrows():\n",
    "    if row['French'] is not None:\n",
    "        lemma = lemmatizer.lemmatize(row['French'])\n",
    "        if row['French'] != lemma:\n",
    "            await retranslator(index)\n",
    "\n",
    "for index, row in df_lexicon_clean.iterrows():\n",
    "    if row['English'] in zulu_stopwords:\n",
    "        df_lexicon_clean = df_lexicon_clean.drop(index)\n",
    "\n",
    "df_lexicon_clean = df_lexicon_clean.dropna(axis=0, subset=[\"English\",\"Zulu\",\"Afrikaans\",\"Sepedi\",\"Xhosa\",\"Shona\",'French'])\n",
    "df_lexicon_clean = df_lexicon_clean.drop_duplicates()\n",
    "print('post lemmatizing french duplicates: ', df_lexicon_clean['French'].duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "21c65b52-094d-4eb9-95a7-be6a054d36fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text samples from corpus:  4640\n",
      "            isiZulu\n",
      "0          <LINE 1>\n",
      "1  Abacwaningi\\tN02\n",
      "2          bathi\\tV\n",
      "3      ukujezisa\\tV\n",
      "4   ngokushaya\\tADV\n"
     ]
    }
   ],
   "source": [
    "# Extracting different text features from the corpus extracted from SADII of news articles in isiZulu\n",
    "file = open('SADII-Ext.Caps.POS.2024-01-31.zu.txt', 'r', encoding='utf-8')\n",
    "lines = file.read()\n",
    "lines = lines.splitlines()\n",
    "file.close()\n",
    "    \n",
    "df_corpus = pd.DataFrame(lines, columns=['isiZulu'])\n",
    "df_corpus['isiZulu'] = df_corpus['isiZulu'].str.strip()\n",
    "\n",
    "print(\"Total text samples from corpus: \", len(df_corpus))\n",
    "print(df_corpus.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc448560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text samples:  465\n",
      "                                             isiZulu\n",
      "0  abacwaningi bathi ukujezisa ngokushaya noma ng...\n",
      "1  abafundi abasebancane kakhulu bona bangakuthok...\n",
      "2                                       abangaphoqwa\n",
      "3  abantu abaningi bayaluthokozela lolu hlelo kwa...\n",
      "4  abantu abasha bakhala ngemfundo yamahhala kany...\n"
     ]
    }
   ],
   "source": [
    "# Cleaning and Tokenization\n",
    "df_corpus_text = pd.DataFrame(columns=['isiZulu'])\n",
    "words = []\n",
    "# Reverse engineering the text samples based on <line> tags\n",
    "text = ''\n",
    "for corpus_text in df_corpus['isiZulu']:\n",
    "    if '<line' in corpus_text.lower():\n",
    "        if text:\n",
    "            text = text.strip().replace('\"', '')\n",
    "            df_corpus_text.loc[len(df_corpus_text)] = text\n",
    "            \n",
    "        text = ''\n",
    "        continue\n",
    "    \n",
    "    tokens = tokenize_text(corpus_text)\n",
    "    text += tokens[0] + ' '\n",
    "    words.append({'isiZulu': tokens[0], 'POS': tokens[1].upper()})\n",
    "\n",
    "df_corpus = pd.DataFrame(words, columns=['isiZulu', 'POS'])\n",
    "print(\"Total text samples: \", len(df_corpus_text))\n",
    "print(df_corpus_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73c301fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial length:  4174\n",
      "final length:  3634\n",
      "       isiZulu          POS\n",
      "0  abacwaningi         Noun\n",
      "1        bathi       Verbal\n",
      "2    ukujezisa       Verbal\n",
      "3   ngokushaya       Adverb\n",
      "4         noma  Conjunction\n"
     ]
    }
   ],
   "source": [
    "# POS Mapping\n",
    "tags = {\n",
    "    \"PUNC\": \"Punctuation\",\n",
    "    \"ABBR\": \"Abbreviation\",\n",
    "    \"ADJ\": \"Adjective\",\n",
    "    \"ADV\": \"Adverb\",\n",
    "    \"ASP\": \"Aspectual marker\",\n",
    "    \"AUX\": \"Auxiliary stem\",\n",
    "    \"CDEM\": \"Class-indicating demonstrative\",\n",
    "    \"CN\": \"Class-indicating nominal prefix\",\n",
    "    \"CO\": \"Class-indicating object concord\",\n",
    "    \"CONJ\": \"Conjunction\",\n",
    "    \"COP\": \"Copulative\",\n",
    "    \"CS\": \"Class-indicating subject concord\",\n",
    "    \"FOR\": \"Foreign\",\n",
    "    \"IDEO\": \"Ideophone\",\n",
    "    \"INT\": \"Interjection\",\n",
    "    \"INTER\": \"Question\",\n",
    "    \"MNEG\": \"Negative morpheme\",\n",
    "    \"N\": \"Noun\",\n",
    "    \"NPP\": \"Noun\",\n",
    "    \"NUM\": \"Numerative\",\n",
    "    \"PART\": \"Particle\",\n",
    "    \"POSS\": \"Possessive\",\n",
    "    \"PROEMP\": \"Emphatic pronoun\",\n",
    "    \"PROQUANT\": \"Quantitative pronoun\",\n",
    "    \"REL\": \"Relative\",\n",
    "    \"TENS\": \"Tense marker\",\n",
    "    \"V\": \"Verbal\",\n",
    "    \"VAUX\": \"Auxiliary verb\"\n",
    "}\n",
    "\n",
    "print('initial length: ', len(df_corpus))\n",
    "df_corpus['POS'] = df_corpus['POS'].map(tags)\n",
    "df_corpus = df_corpus[df_corpus['POS'] != 'Punctuation']\n",
    "print('final length: ', len(df_corpus))\n",
    "print(df_corpus.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e3feba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus translation in progress\n",
      "                                             isiZulu  \\\n",
      "0  abacwaningi bathi ukujezisa ngokushaya noma ng...   \n",
      "1  abafundi abasebancane kakhulu bona bangakuthok...   \n",
      "2                                       abangaphoqwa   \n",
      "3  abantu abaningi bayaluthokozela lolu hlelo kwa...   \n",
      "4  abantu abasha bakhala ngemfundo yamahhala kany...   \n",
      "\n",
      "                                             English Sentiment  \n",
      "0  researchers say that punishing by beating, no ...  Negative  \n",
      "1  Younger readers can enjoy reading texts with l...  Positive  \n",
      "2                               who cannot be forced  Positive  \n",
      "3  Many people enjoy this program because even a ...  Positive  \n",
      "4  young people are complaining about free educat...  Negative  \n"
     ]
    }
   ],
   "source": [
    "english_text = []\n",
    "sentiment_result = []\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "print('Corpus translation in progress')\n",
    "for sentence in df_corpus_text['isiZulu']:\n",
    "    translated_text = GoogleTranslator(source='auto', target='en').translate(sentence)\n",
    "    sentiment_dict = analyzer.polarity_scores(translated_text)\n",
    "    \n",
    "    english_text.append(translated_text)\n",
    "    if sentiment_dict['compound'] >= 0.05:\n",
    "        sentiment_result.append('Positive')     \n",
    "    elif sentiment_dict['compound'] <= - 0.05:\n",
    "        sentiment_result.append('Negative')   \n",
    "    else:\n",
    "        sentiment_result.append('Neutral')   \n",
    "\n",
    "df_corpus_text['English'] = english_text\n",
    "df_corpus_text['Sentiment'] = sentiment_result\n",
    "print(df_corpus_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f636864f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pre-cleansed samples:  465\n",
      "Number of post-cleansed samples:  465\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of pre-cleansed samples: \", len(df_corpus_text))\n",
    "# Clean untranslated text samples\n",
    "for index, row in df_corpus_text.iterrows():\n",
    "    detect = await translator.detect(row['English'])\n",
    "    if detect.lang != 'en':\n",
    "        try:\n",
    "            translated = await translator.translate(row['English'], src=detect.lang, dest='en')\n",
    "            df_corpus_text.at[index, 'English'] = translated.text\n",
    "        except:\n",
    "            df_corpus_text.drop(index, inplace=True)\n",
    "\n",
    "print(\"Number of post-cleansed samples: \", len(df_corpus_text))\n",
    "df_corpus_text.to_csv('./corpus_datasets/Zulu_to_English_Corpus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f6fa18bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\116su\\AppData\\Local\\Temp\\ipykernel_4384\\577754292.py:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  df_lexicon = pd.read_csv('.\\corpus_datasets\\Zulu_to_English_Corpus.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens for PMI (after removing stopwords): 3374\n",
      "Top positive candidate words:\n",
      "         word  PMI_Pos  PMI_Neg  PMI_Diff\n",
      "28       lolu      1.0     -2.0       3.0\n",
      "16   ukufunda      0.0     -2.0       2.0\n",
      "422     bhala      0.0     -2.0       2.0\n",
      "438      kulo      0.0     -2.0       2.0\n",
      "453     yakho      0.0     -2.0       2.0\n",
      "\n",
      "Top negative candidate words:\n",
      "               word  PMI_Pos  PMI_Neg  PMI_Diff\n",
      "67          abazali     -2.0      1.0      -3.0\n",
      "74           izinto     -2.0      1.0      -3.0\n",
      "1476         inyama     -2.0      1.0      -3.0\n",
      "265           kepha     -2.0      1.0      -3.0\n",
      "103            kuba     -2.0      1.0      -3.0\n",
      "2138        akhiphe      0.0      2.0      -2.0\n",
      "2137   ephoqelekile      0.0      2.0      -2.0\n",
      "2136      wazithola      0.0      2.0      -2.0\n",
      "2112        indlamu      0.0      2.0      -2.0\n",
      "2111     ukuzehlisa      0.0      2.0      -2.0\n",
      "2110        emkhuza      0.0      2.0      -2.0\n",
      "2109     owayehlala      0.0      2.0      -2.0\n",
      "2108       komkakhe      0.0      2.0      -2.0\n",
      "2107     ukuthoshwa      0.0      2.0      -2.0\n",
      "2106  wayengathandi      0.0      2.0      -2.0\n",
      "2105     umhlangano      0.0      2.0      -2.0\n",
      "2104    wawuhlakaza      0.0      2.0      -2.0\n",
      "2057       eseqonde      0.0      2.0      -2.0\n",
      "2056      ngejubane      0.0      2.0      -2.0\n",
      "2055        wahlaba      0.0      2.0      -2.0\n"
     ]
    }
   ],
   "source": [
    "df_lexicon = pd.read_csv('.\\corpus_datasets\\Zulu_to_English_Corpus.csv')\n",
    "\n",
    "df_words = []\n",
    "for idx, row in df_lexicon.iterrows():\n",
    "    words = row['isiZulu'].lower().split()\n",
    "    for w in words:\n",
    "        # Remove punctuation\n",
    "        w = w.strip('.,!?;\"()[]{}')\n",
    "        # Skip empty strings and stopwords\n",
    "        if w and w not in zulu_stopwords:\n",
    "            w = lemmatizer.lemmatize(w)\n",
    "            df_words.append({'tokens': w, 'label': row['Sentiment'].lower()})\n",
    "\n",
    "df_tokens_labeled = pd.DataFrame(df_words)\n",
    "\n",
    "print(f\"Total tokens for PMI (after removing stopwords): {len(df_tokens_labeled)}\")\n",
    "\n",
    "pos_tokens = df_tokens_labeled[df_tokens_labeled['label'] == 'positive']['tokens'].tolist()\n",
    "neg_tokens = df_tokens_labeled[df_tokens_labeled['label'] == 'negative']['tokens'].tolist()\n",
    "\n",
    "pos_counts = Counter(pos_tokens)\n",
    "neg_counts = Counter(neg_tokens)\n",
    "all_counts = Counter(df_tokens_labeled['tokens'])\n",
    "\n",
    "total_pos = sum(pos_counts.values())\n",
    "total_neg = sum(neg_counts.values())\n",
    "total_all = sum(all_counts.values())\n",
    "\n",
    "\n",
    "pmi_data = []\n",
    "for word in all_counts:\n",
    "    p_word = all_counts[word] / total_all\n",
    "    pmi_pos = np.floor(math.log2((pos_counts[word]/total_pos)/p_word) if word in pos_counts else 0)\n",
    "    pmi_neg = np.floor(math.log2((neg_counts[word]/total_neg)/p_word) if word in neg_counts else 0)\n",
    "    pmi_diff = np.floor(pmi_pos - pmi_neg)\n",
    "    pmi_data.append((word, pmi_pos, pmi_neg, pmi_diff))\n",
    "\n",
    "df_pmi = pd.DataFrame(pmi_data, columns=['word', 'PMI_Pos', 'PMI_Neg', 'PMI_Diff'])\n",
    "\n",
    "positive_candidates = df_pmi[df_pmi['PMI_Diff'] > 1].sort_values(by='PMI_Diff', ascending=False)\n",
    "negative_candidates = df_pmi[df_pmi['PMI_Diff'] < -1].sort_values(by='PMI_Diff', ascending=True)\n",
    "\n",
    "print(\"Top positive candidate words:\")\n",
    "print(positive_candidates.head(20))\n",
    "\n",
    "print(\"\\nTop negative candidate words:\")\n",
    "print(negative_candidates.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e93242e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexicon Columns: ['Unnamed: 0', 'CILUBA', 'French', 'Score', 'Sentiment', 'Nature', 'English', 'Zulu', 'Afrikaans', 'Sepedi', 'Xhosa', 'Shona']\n",
      "\n",
      "✅ Sentiment Comparison Summary:\n",
      "Match\n",
      "Mismatch    337\n",
      "Match        36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample mismatched entries:\n",
      "           Zulu     English Sentiment Nature PMI_Sentiment  Score  PMI_Diff\n",
      "0        ihlaya        joke   postive    mot      positive    8.0       1.0\n",
      "1      isilwane    creature   postive    mot      negative    1.0      -2.0\n",
      "2       iqiniso       truth   postive    mot       neutral    8.0       0.0\n",
      "3        abantu      people   postive    mot       neutral    1.0       0.0\n",
      "4      ukuhamba        walk   postive  verbe       neutral    7.0       0.0\n",
      "5  ukuqondisisa  understand   postive  verbe      negative    2.0      -2.0\n",
      "6         ngena       enter   postive  verbe       neutral    1.0       0.0\n",
      "7        umuntu      person   postive    mot      negative    1.0      -1.0\n",
      "8         umoya         air   postive    mot      positive    4.0       1.0\n",
      "9       phawula     observe   postive  verbe       neutral    3.0       0.0\n",
      "\n",
      "✅ Saved matched entries to: ./comparison_outputs/zulu_sentiment_matches.csv\n",
      "⚠️ Saved mismatched entries (for RAG/LLM review) to: ./comparison_outputs/zulu_sentiment_mismatches.csv\n"
     ]
    }
   ],
   "source": [
    "# --- CONTINUATION FROM YOUR PMI CODE ---\n",
    "\n",
    "# Load the cleaned multilingual lexicon (ensure path matches your project)\n",
    "lexicon_path = './lexicon_dataset/expanded_lexicon_cleaned.xlsx'\n",
    "df_lexicon = pd.read_excel(lexicon_path)\n",
    "\n",
    "# Make sure column names match what was created earlier\n",
    "# (e.g., \"Zulu\", \"English\", \"Sentiment\")\n",
    "print(\"Lexicon Columns:\", df_lexicon.columns.tolist())\n",
    "\n",
    "# Derive a corpus-based sentiment label from PMI difference\n",
    "df_pmi['PMI_Sentiment'] = df_pmi['PMI_Diff'].apply(\n",
    "    lambda x: 'positive' if x > 0.5 else ('negative' if x < -0.5 else 'neutral')\n",
    ")\n",
    "\n",
    "# Merge PMI results (Zulu words) with lexicon (Zulu column)\n",
    "merged_df = df_lexicon.merge(df_pmi, left_on='Zulu', right_on='word', how='inner')\n",
    "\n",
    "# Compare polarity between lexicon sentiment and corpus (PMI-based) sentiment\n",
    "merged_df['Match'] = np.where(\n",
    "    merged_df['Sentiment'].str.lower() == merged_df['PMI_Sentiment'], \n",
    "    'Match', \n",
    "    'Mismatch'\n",
    ")\n",
    "\n",
    "# --- Basic Statistics ---\n",
    "print(\"\\n✅ Sentiment Comparison Summary:\")\n",
    "print(merged_df['Match'].value_counts())\n",
    "print(\"\\nSample mismatched entries:\")\n",
    "print(merged_df[merged_df['Match'] == 'Mismatch'][['Zulu', 'English', 'Sentiment', 'Nature', 'PMI_Sentiment', 'Score', 'PMI_Diff']].head(10))\n",
    "\n",
    "# --- Save outputs for review ---\n",
    "output_match = './comparison_outputs/zulu_sentiment_matches.csv'\n",
    "output_mismatch = './comparison_outputs/zulu_sentiment_mismatches.csv'\n",
    "\n",
    "import os\n",
    "os.makedirs('./comparison_outputs', exist_ok=True)\n",
    "\n",
    "merged_df[merged_df['Match'] == 'Match'].to_csv(output_match, index=False)\n",
    "merged_df[merged_df['Match'] == 'Mismatch'].to_csv(output_mismatch, index=False)\n",
    "\n",
    "print(f\"\\n✅ Saved matched entries to: {output_match}\")\n",
    "print(f\"⚠️ Saved mismatched entries (for RAG/LLM review) to: {output_mismatch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3b678ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It learns patterns from data to make predictions or decisions.\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd71e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "composure to become a standing joke with Mrs . Jennings .. imagined it to be a joke for the good of her. it was rather his favourite joke of the two , as. to her a very good joke , and which she treated. it had been only a joke , but so serious a. young man I used to joke with you about ( but. may treat it as a joke ,\" said he , at. \n",
      "Word:  joke\n",
      "Adjusted Polarity (RAG/LLM): 0.2\n",
      "Adjusted Polarity (Vader): 0.296\n",
      "Polarity (Corpus Enrichment): 1.0\n",
      "Original Polarity (lexicon): 8.0\n",
      "\n",
      "I am with any other creature in the world , except. hardly be outdone by any creature professedly noisy . The mother. that I have not a creature whose advice I can ask. is such a sly little creature , there is no finding. she is quite an altered creature . I hope , from. I could rather believe every creature of my acquaintance leagued together. three , is there a creature in the world whom I. dear !-- And not a creature knowing a syllable of the. is a well - meaning creature , but no conjurer ,. of it to a single creature ; knowing that it would. a very good - hearted creature ; as well - meaning. on , she left no creature behind , from whom it. therefore so tediously -- no creature to speak to -- my. the vanity of any living creature , how could I suppose. \n",
      "Word:  creature\n",
      "Adjusted Polarity (RAG/LLM): -0.2\n",
      "Adjusted Polarity (Vader): 0.0\n",
      "Polarity (Corpus Enrichment): -2.0\n",
      "Original Polarity (lexicon): 1.0\n",
      "\n",
      "Indeed , to say the truth , I am convinced within. and herself had outstripped the truth . \" And you really. called a beautiful girl , truth was less violently outraged than. so let us hear the truth of it .\" \" My. give anything to know the truth of it . Perhaps it. him . There is great truth , however , in what. Elinor could not deny the truth of this , and she. guard every suspicion of the truth from her mother and sisters. to have found out the truth in an instant , if. a while by owning the truth ?\" \" If we could. be less when the whole truth were revealed , and now. the fact . Whatever the truth of it might be ,. : and to say the truth it was not very pretty. the enforcement of the real truth . After a short silence. -- there may be more truth in it than I could. came determined to know the truth ; though irresolute what to. Marianne appeared to distrust the truth of any part of it. which , to say the truth , has been a little. certainly not at all on truth . They were relieved however. fancy to so far outrun truth and probability , that on. her acquainted with the real truth , and in endeavouring to. giving any hint of the truth ; and I owed it. nothing to my solicitation .\" Truth obliged her to acknowledge some. to be satisfied of the truth . She instantly saw that. to declare only the simple truth , and lay open such. the reality of reason and truth , one of the happiest. , though perfectly admitting the truth of her representation , he. \n",
      "Word:  truth\n",
      "Adjusted Polarity (RAG/LLM): 0.55\n",
      "Adjusted Polarity (Vader): 0.3182\n",
      "Polarity (Corpus Enrichment): 0.0\n",
      "Original Polarity (lexicon): 8.0\n",
      "\n",
      "to the comfort of other people she could act when occasion. but if you observe , people always live for ever when. seeing the performances of other people , and I assure you. by the drawings of other people , was very far from. collecting about him more young people than his house would hold. weddings among all the young people of her acquaintance . She. giving his opinion of other people , in sacrificing general politeness. perhaps the abuse of such people as yourself and Marianne will. be insufficient to make some people acquainted with each other ,. the various endeavours of different people to quit the topic ,. , \" There are some people who cannot bear a party. ? Are the Middletons pleasant people ?\" \" No , not. replied , \" But most people do .\" \" I wish. point or other : fancying people so much more gay or. very frequently by what other people say of them , without. by the opinion of other people . I thought our judgments. . Because he believes many people pretend to more admiration of. his house ? How few people know what comfort is !. of appearing superior to other people . The motive was too. election ; and so many people came to dine with us. I do not believe many people are acquainted with him ,. failed , as between many people , and under many circumstances. the power of dividing two people so tenderly attached is too. separately from that of other people , you will scarcely have. him , nearly twenty young people , and to amuse them. and remarks of all these people . The Middletons and Palmers. , and you know young people like to be laughed at. . She expected from other people the same opinions and feelings. Miss Dashwoods found so many people before them in the room. to be ; they are people of large fortune , they. dare say , as many people suppose . I do not. to her income . Few people of common prudence will do. to recollect himself , \" people have little , have very. words ; for , unlike people in general , she proportioned. while the imaginations of other people will carry them away to. not enough ; for when people are determined on a mode. , comprehended a great many people who had real taste for. of it . \" Some people imagine that there can be. , you see , if people do but know how to. I have no notion of people ' s making such a. ,\" speaking triumphantly , \" people may say what they chuse. was no business of other people to set it down for. Dashwood , do you think people make love when any body. you they are very genteel people . He makes a monstrous. to divide , two young people long attached to each other. and SHE , of all people in the world , was. he has done . Few people who have so compassionate a. though she returned from seeing people whom she had never seen. himself as much superior to people in general , as he. the habit of associating with people of better income than myself. their genuine attention to other people , and their manly unstudied. friendly and hospitable for other people as well as herself ,. happen -- for , when people are much thrown together ,. , might have puzzled many people to find out ; and. \n",
      "Word:  people\n",
      "Adjusted Polarity (RAG/LLM): -0.1\n",
      "Adjusted Polarity (Vader): 0.0\n",
      "Polarity (Corpus Enrichment): 0.0\n",
      "Original Polarity (lexicon): 1.0\n",
      "\n",
      "any change in those who walk under your shade !-- But. beyond the distance of a walk . There were but few. ?-- Margaret , we will walk here at least two hours. morning , for we must walk to the park , to. her sisters in their usual walk , instead of wandering away. If her sisters intended to walk on the downs , she. surrounding country ; in his walk to the village , he. able to take your usual walk to Allenham today .\" Marianne. wanted the whole family to walk to the Park directly and. at their indifference , to walk home and boast anew of. of their joining in a walk , where they might most. , he asked Elinor to walk with him to Conduit Street. as great an inclination to walk out of the room again. says , she could hardly walk ; and Nancy , she. shrubbery , and closer wood walk , a road of smooth. had depended on a twilight walk to the Grecian temple ,. every day . We will walk to the farm at the. go on ; we will walk to Sir John ' s. arm , was authorised to walk as long as she could. be surprised to see him walk in today or tomorrow ,. \n",
      "Word:  walk\n",
      "Adjusted Polarity (RAG/LLM): 0.0\n",
      "Adjusted Polarity (Vader): 0.0\n",
      "Polarity (Corpus Enrichment): 0.0\n",
      "Original Polarity (lexicon): 7.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "text_words = gutenberg.words('austen-sense.txt')\n",
    "context_size = 5\n",
    "df_mismatches = pd.read_csv('./comparison_outputs/zulu_sentiment_mismatches.csv')\n",
    "\n",
    "def get_baseline_polarity(text):\n",
    "    \"\"\"Calculates the baseline VADER compound polarity score.\"\"\"\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "def adjust_polarity_with_rag(text, retrieved_context):\n",
    "    \"\"\"\n",
    "    Uses an LLM (Gemini) to adjust the polarity score based on context.\n",
    "    \"\"\"\n",
    "    baseline_score = get_baseline_polarity(text)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    The original word is: \"{text}\"\n",
    "    The original sentiment polarity score is: {baseline_score}\n",
    "\n",
    "    Here is some specific context related to the text:\n",
    "    \"{retrieved_context}\"\n",
    "\n",
    "    Based ONLY on the provided context, re-evaluate the sentiment polarity of the original text. \n",
    "    Provide a revised score between -1.0 (negative) and 1.0 (positive). \n",
    "    If the context doesn't change the meaning, keep the original score.\n",
    "\n",
    "    Respond strictly in JSON format like:\n",
    "    {{\n",
    "        \"adjusted_score\": <float>\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=prompt\n",
    "        )\n",
    "\n",
    "        # Gemini returns text output, not a JSON object — so parse manually\n",
    "        if hasattr(response, \"text\") and response.text:\n",
    "            text_response = response.text.strip().replace('```', '').replace('json', '')\n",
    "            try:\n",
    "                parsed_json = json.loads(text_response)\n",
    "                return float(parsed_json.get(\"adjusted_score\", baseline_score))\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"⚠️ Could not parse JSON from model response:\\n{text_response}\")\n",
    "                return baseline_score\n",
    "        else:\n",
    "            print(\"⚠️ No text response from Gemini model.\")\n",
    "            return baseline_score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error with Gemini API call: {e}\")\n",
    "        return baseline_score\n",
    "\n",
    "# Get adjusted scores\n",
    "for index, row in df_mismatches[].iterrows():\n",
    "    weights = {\n",
    "        'count_zero': 0,\n",
    "        'count_positve': 0,\n",
    "        'count_negative': 0,\n",
    "    }\n",
    "    \n",
    "    found_contexts = []\n",
    "    for i, word in enumerate(text_words):\n",
    "        if word.lower() == row['English'].lower():\n",
    "            start_index = max(0, i - context_size)\n",
    "            end_index = min(len(text_words), i + context_size + 1)\n",
    "            context = text_words[start_index:end_index]\n",
    "            found_contexts.append(\" \".join(context))\n",
    "            \n",
    "    domain_texts = ''\n",
    "    for text in found_contexts:\n",
    "        domain_texts += f'{text}. '\n",
    "    \n",
    "    print(domain_texts)\n",
    "    adjusted_score = adjust_polarity_with_rag(row['English'], domain_texts)\n",
    "\n",
    "    if adjusted_score > 0:\n",
    "        weights['count_positve'] += 1\n",
    "    elif adjusted_score < 0:\n",
    "        weights['count_negative'] += 1\n",
    "    else:\n",
    "        weights['count_zero'] += 1\n",
    "    \n",
    "    print('Word: ', row['English'])\n",
    "    print(f\"Adjusted Polarity (RAG/LLM): {adjusted_score}\")\n",
    "    \n",
    "    baseline = get_baseline_polarity(row['English'])\n",
    "    if baseline > 0:\n",
    "        weights['count_positve'] += 1\n",
    "    elif baseline < 0:\n",
    "        weights['count_negative'] += 1\n",
    "    else:\n",
    "        weights['count_zero'] += 1\n",
    "    print(f\"Adjusted Polarity (Vader): {baseline}\")\n",
    "    \n",
    "    if row['PMI_Diff'] > 0:\n",
    "        weights['count_positve'] += 1\n",
    "    elif row['PMI_Diff'] < 0:\n",
    "        weights['count_negative'] += 1\n",
    "    else:\n",
    "        weights['count_zero'] += 1\n",
    "    print(f\"Polarity (Corpus Enrichment): {row['PMI_Diff']}\")\n",
    "    \n",
    "    if row['Score'] > 0:\n",
    "        weights['count_positve'] += 1\n",
    "    elif row['Score'] < 0:\n",
    "        weights['count_negative'] += 1\n",
    "    else:\n",
    "        weights['count_zero'] += 1\n",
    "    print(f\"Original Polarity (lexicon): {row['Score']}\\n\")\n",
    "\n",
    "    mk = None # max_key\n",
    "    mv = float('-inf') # max_value\n",
    "\n",
    "    for k, v in weights.items():\n",
    "        if v > mv:\n",
    "            mv = v\n",
    "            mk = k\n",
    "            \n",
    "    i = df_lexicon_clean[df_lexicon_clean['English'] == row['English']]\n",
    "    df_lexicon_clean.at[i.index[0], 'Sentiment'] = 'positive' if mk == 'count_positve' else 'negative' if mk == 'count_negative' else 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7190f608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CILUBA     French  Score Sentiment Nature    English  \\\n",
      "0      akaja    arrange    1.0   postive  verbe    arrange   \n",
      "1  akajilula  rearrange    1.0   postive  verbe  rearrange   \n",
      "2      akula      parle    2.0   postive  verbe      speak   \n",
      "3    akulula    reparle    2.0   postive  verbe      speak   \n",
      "4      aluja      remet    3.0   postive  verbe      hands   \n",
      "\n",
      "                 Zulu   Afrikaans               Sepedi               Xhosa  \\\n",
      "0               hlela        reël             beakanya           cwangcisa   \n",
      "1    ibanga langemuva  agterreeks  range ya ka morao .  uluhlu lwangasemva   \n",
      "2             khuluma       praat               bolela              thetha   \n",
      "3       khuluma futhi  praat weer        bolela gape .     thetha kwakhona   \n",
      "4  izandla ngaphezulu   hande oor   diatla godimo ga .  izandla ngaphezulu   \n",
      "\n",
      "            Shona  \n",
      "0           ronga  \n",
      "1       kumashure  \n",
      "2           taura  \n",
      "3   taura zvakare  \n",
      "4  maoko pamusoro  \n"
     ]
    }
   ],
   "source": [
    "print(df_lexicon_clean.head())\n",
    "df_lexicon_clean.to_excel('./lexicon_dataset/expanded_lexicon_cleaned.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
